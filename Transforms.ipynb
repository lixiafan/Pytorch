{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3333, 0.2863, 0.2784,  ..., 0.5765, 0.5961, 0.6000],\n",
      "         [0.2510, 0.2784, 0.2863,  ..., 0.5569, 0.6078, 0.6196],\n",
      "         [0.2510, 0.3137, 0.3059,  ..., 0.5294, 0.5451, 0.5765],\n",
      "         ...,\n",
      "         [0.4824, 0.4902, 0.4941,  ..., 0.3725, 0.3725, 0.3804],\n",
      "         [0.4902, 0.4941, 0.4941,  ..., 0.3725, 0.3725, 0.3804],\n",
      "         [0.4902, 0.4941, 0.4941,  ..., 0.3725, 0.3725, 0.3804]],\n",
      "\n",
      "        [[0.3490, 0.2941, 0.2941,  ..., 0.5137, 0.5255, 0.5451],\n",
      "         [0.2627, 0.2941, 0.2980,  ..., 0.4902, 0.5412, 0.5608],\n",
      "         [0.2784, 0.3333, 0.3255,  ..., 0.4588, 0.4745, 0.5059],\n",
      "         ...,\n",
      "         [0.4196, 0.4196, 0.4235,  ..., 0.3647, 0.3647, 0.3608],\n",
      "         [0.4196, 0.4235, 0.4235,  ..., 0.3647, 0.3647, 0.3608],\n",
      "         [0.4196, 0.4235, 0.4235,  ..., 0.3647, 0.3647, 0.3608]],\n",
      "\n",
      "        [[0.2588, 0.2000, 0.2039,  ..., 0.4627, 0.4784, 0.5098],\n",
      "         [0.1804, 0.2039, 0.2157,  ..., 0.4588, 0.5137, 0.5412],\n",
      "         [0.1569, 0.2078, 0.2078,  ..., 0.4510, 0.4745, 0.5059],\n",
      "         ...,\n",
      "         [0.2196, 0.2235, 0.2353,  ..., 0.2667, 0.2667, 0.2824],\n",
      "         [0.2235, 0.2275, 0.2353,  ..., 0.2667, 0.2667, 0.2824],\n",
      "         [0.2235, 0.2275, 0.2353,  ..., 0.2667, 0.2667, 0.2824]]])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"logs1\")\n",
    "image_path = \"C:/Users/19937/Pictures/Camera Roll/20230103.jpg\"\n",
    "img_PIL = Image.open(image_path)\n",
    "# img_PIL.show()\n",
    "# ToTensor()\n",
    "tensor_trans = transforms.ToTensor()\n",
    "tensor_img = tensor_trans(img_PIL)\n",
    "print(tensor_img)\n",
    "writer.add_image(\"Tensor_img\",tensor_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3333)\n",
      "tensor(-0.3333)\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "# input[channel] = (input[channel] - mean[channel]) / std[channel]\n",
    "print(tensor_img[0][0][0])\n",
    "trans_norm = transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "img_norm = trans_norm(tensor_img)\n",
    "print(img_norm[0][0][0])\n",
    "writer.add_image(\"Normalize\",img_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1921, 1080)\n",
      "<built-in method size of Tensor object at 0x0000025721F1E7E0>\n"
     ]
    }
   ],
   "source": [
    "# Resize\n",
    "print(img_PIL.size)\n",
    "trans_resize = transforms.Resize((512,512))\n",
    "img_resize = trans_resize(img_PIL)\n",
    "img_resize = tensor_trans(img_resize)\n",
    "writer.add_image(\"Resize\",img_resize)\n",
    "print(img_resize.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compose : 将Resize和ToTensor方法打包\n",
    "#trans_resize_2 = transforms.Resize(512)\n",
    "#trans_totensor= transforms.ToTensor()\n",
    "#trans_compose = transforms.Compose([trans_resize_2,trans_totensor])\n",
    "trans_compose = transforms.Compose([transforms.Resize(512),transforms.ToTensor()])\n",
    "img_resize_2 = trans_compose(img_PIL)\n",
    "writer.add_image(\"Compose\",img_resize_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomCrop\n",
    "trans_random = transforms.RandomCrop((500,1000))\n",
    "trans_compose_2 = transforms.Compose([trans_random,tensor_trans])\n",
    "# 不同的步数可以看到不同的结果\n",
    "for i in range(10):\n",
    "    img_crop = trans_compose_2(img_PIL)\n",
    "    writer.add_image(\"RandomCrop\",img_crop,i)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "cv_img = cv2.imread(image_path)\n",
    "print(type(cv_img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__call__hello zhangsan\n",
      "hello  lisi\n"
     ]
    }
   ],
   "source": [
    "class Person:\n",
    "    def __call__(self,name):\n",
    "        print(\"__call__\"+\"hello \"+name)\n",
    "    def hello(self,name):\n",
    "        print(\"hello \",name)\n",
    "        \n",
    " # 调用函数的两种方式：\n",
    "person = Person()\n",
    "person(\"zhangsan\")#调用的是__call__函数\n",
    "person.hello(\"lisi\")#调用hello()函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
