{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision \n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import Conv2d,MaxPool2d,Linear,Sequential,Flatten,CrossEntropyLoss\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "# 搭建神经网络\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.model1 = Sequential(\n",
    "            Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "            MaxPool2d(kernel_size=2),\n",
    "            Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "            MaxPool2d(kernel_size=2),\n",
    "            Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2),\n",
    "            MaxPool2d(kernel_size=2),\n",
    "            Flatten(),\n",
    "            Linear(in_features=1024, out_features=64),\n",
    "            Linear(in_features=64, out_features=10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model1(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "# 准备数据集\n",
    "train_data = torchvision.datasets.CIFAR10(root='../dataset',train=True,transform=torchvision.transforms.ToTensor(),download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root='../dataset',train=False,transform=torchvision.transforms.ToTensor(),download=True)\n",
    "train_data_len = len(train_data)\n",
    "test_data_len = len(test_data)\n",
    "# print(\"训练数据的长度为： {}\".format(train_data_len)) # 50000\n",
    "# print(\"测试数据的长度为： {}\".format(test_data_len)) # 10000\n",
    "\n",
    "# 利用dataloader加载数据集\n",
    "train_dataloader = DataLoader(train_data,batch_size=64)\n",
    "test_dataloader = DataLoader(test_data,batch_size=64)\n",
    "\n",
    "# 创建网络模型\n",
    "model = Model()\n",
    "if torch.cuda.is_available():####################\n",
    "    model = model.cuda()###################\n",
    "\n",
    "# 定义损失函数\n",
    "loss_fn = CrossEntropyLoss()\n",
    "if torch.cuda.is_available():####################\n",
    "    loss_fn = loss_fn.cuda()####################\n",
    "\n",
    "# 定义优化器\n",
    "learning_rate = 0.01 # 1e-2\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "\n",
    "# 设置训练网络的参数\n",
    "# 记录训练的次数\n",
    "total_train_step = 0\n",
    "# 记录测试的次数\n",
    "total_test_step = 0\n",
    "# 训练的轮数\n",
    "epoch = 10\n",
    "\n",
    "# 添加tensorboard\n",
    "writer = SummaryWriter(\"../logs_model\")\n",
    "start_time = time.time()\n",
    "for i in range(epoch):\n",
    "    print(\"----------第 {} 轮训练开始------------\".format(i+1))\n",
    "\n",
    "    # 训练步骤开始\n",
    "    # model.train()\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data # 获取数据\n",
    "        if torch.cuda.is_available():####################\n",
    "            imgs = imgs.cuda()###########################\n",
    "            targets = targets.cuda()#########################\n",
    "        outputs = model(imgs) # 输入模型后得到预测输出\n",
    "        loss = loss_fn(outputs,targets) # 计算预测输出和数据集中的真实标签的损失\n",
    "\n",
    "        # 优化器优化模型\n",
    "        optimizer.zero_grad() # 将优化器的梯度清零\n",
    "        loss.backward() # loss反向传播\n",
    "        optimizer.step() # 开始使用优化器进行优化\n",
    "\n",
    "        total_train_step += 1 # 训练步加一\n",
    "        if total_train_step % 100 == 0:\n",
    "            end_time = time.time()\n",
    "            print(\"训练了{}次所用的时间：\".format(total_train_step),end_time-start_time)\n",
    "            print(\"训练次数: {},  Loss: {}\".format(total_train_step, loss.item()))\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), total_train_step)\n",
    "\n",
    "    # 每训练完一轮，在测试集上进行评估，判断模型的参数有没有训练好\n",
    "    # 测试步骤开始\n",
    "    # model.eval()\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 9\n",
    "    with torch.no_grad(): # 不进行调优\n",
    "        for data in test_dataloader:\n",
    "            imgs, targets = data\n",
    "            if torch.cuda.is_available():####################\n",
    "                imgs = imgs.cuda()#######################\n",
    "                targets = targets.cuda()########################\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs,targets)\n",
    "            total_test_loss += loss.item()\n",
    "            accuracy = (outputs.argmax(1) == targets).sum()\n",
    "            total_accuracy += accuracy\n",
    "    test_accuracy = torch.true_divide(total_accuracy, test_data_len)\n",
    "    print(\"整体测试集上的loss： {}\".format(total_test_loss))\n",
    "    print(\"整体测试集上的正确率：{}\".format(test_accuracy))\n",
    "    writer.add_scalar(\"test_loss\", total_test_loss, total_test_step)\n",
    "    writer.add_scalar(\"test_accuracy\", test_accuracy, total_test_step)\n",
    "    total_test_step += 1\n",
    "\n",
    "    # 测试完之后保存模型的参数\n",
    "    torch.save(model,\"./weight/model_{}.pth\".format(i))\n",
    "    # torch.save(model.state_dict(), \"model_{}\".format(i)) # 官方推荐的网络模型的保存方式\n",
    "    print(\"模型已保存！\")\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "----------第 1 轮训练开始------------\n",
      "训练了100次所用的时间： 8.272866249084473\n",
      "训练次数: 100,  Loss: 2.2943379878997803\n",
      "WARNING:tensorflow:From C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\distributions\\distribution.py:265: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\distributions\\bernoulli.py:169: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-fb51ef6d88cd>\", line 81, in <module>\n",
      "    loss.backward() # loss反向传播\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\torch\\tensor.py\", line 185, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\torch\\autograd\\__init__.py\", line 127, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1806, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 941, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 45, in <module>\n",
      "    from . _api.v2 import compat\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\__init__.py\", line 23, in <module>\n",
      "    from . import v1\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\__init__.py\", line 40, in <module>\n",
      "    from . import experimental\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\experimental\\__init__.py\", line 11, in <module>\n",
      "    from tensorflow.python.ops.control_flow_v2_toggles import output_all_intermediates\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\control_flow_v2_toggles.py\", line 24, in <module>\n",
      "    from tensorflow.python.ops import control_flow_util_v2\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\control_flow_util_v2.py\", line 28, in <module>\n",
      "    from tensorflow.python.keras.engine import base_layer_utils\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\__init__.py\", line 27, in <module>\n",
      "    from tensorflow.python.keras import applications\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\applications\\__init__.py\", line 25, in <module>\n",
      "    from tensorflow.python.keras import engine\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\__init__.py\", line 23, in <module>\n",
      "    from tensorflow.python.keras.engine.base_layer import Layer\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\", line 56, in <module>\n",
      "    from tensorflow.python.keras.saving.saved_model import layer_serialization\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\__init__.py\", line 20, in <module>\n",
      "    from tensorflow.python.keras.saving.hdf5_format import load_attributes_from_hdf5_group\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\hdf5_format.py\", line 32, in <module>\n",
      "    from tensorflow.python.keras.utils import conv_utils\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\__init__.py\", line 38, in <module>\n",
      "    from tensorflow.python.keras.utils.multi_gpu_utils import multi_gpu_model\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\multi_gpu_utils.py\", line 22, in <module>\n",
      "    from tensorflow.python.keras.engine.training import Model\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 42, in <module>\n",
      "    from tensorflow.python.keras import metrics as metrics_module\n",
      "  File \"C:\\Users\\19937\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\metrics.py\", line 34, in <module>\n",
      "    from tensorflow.python.keras.engine.base_layer import Layer\n",
      "ImportError: cannot import name 'Layer'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import torchvision \n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import Conv2d,MaxPool2d,Linear,Sequential,Flatten,CrossEntropyLoss\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "# 搭建神经网络\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.model1 = Sequential(\n",
    "            Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "            MaxPool2d(kernel_size=2),\n",
    "            Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "            MaxPool2d(kernel_size=2),\n",
    "            Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2),\n",
    "            MaxPool2d(kernel_size=2),\n",
    "            Flatten(),\n",
    "            Linear(in_features=1024, out_features=64),\n",
    "            Linear(in_features=64, out_features=10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model1(x)\n",
    "        return x\n",
    "\n",
    "# 指定训练的设备\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# 准备数据集\n",
    "train_data = torchvision.datasets.CIFAR10(root='./dataset',train=True,transform=torchvision.transforms.ToTensor(),download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root='./dataset',train=False,transform=torchvision.transforms.ToTensor(),download=True)\n",
    "train_data_len = len(train_data)\n",
    "test_data_len = len(test_data)\n",
    "# print(\"训练数据的长度为： {}\".format(train_data_len)) # 50000\n",
    "# print(\"测试数据的长度为： {}\".format(test_data_len)) # 10000\n",
    "\n",
    "# 利用dataloader加载数据集\n",
    "train_dataloader = DataLoader(train_data,batch_size=64)\n",
    "test_dataloader = DataLoader(test_data,batch_size=64)\n",
    "\n",
    "# 创建网络模型\n",
    "model = Model()\n",
    "model.to(device)###################\n",
    "\n",
    "# 定义损失函数\n",
    "loss_fn = CrossEntropyLoss()\n",
    "loss_fn.to(device)####################\n",
    "\n",
    "# 定义优化器\n",
    "learning_rate = 0.01 # 1e-2\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "\n",
    "# 设置训练网络的参数\n",
    "# 记录训练的次数\n",
    "total_train_step = 0\n",
    "# 记录测试的次数\n",
    "total_test_step = 0\n",
    "# 训练的轮数\n",
    "epoch = 10\n",
    "\n",
    "# 添加tensorboard\n",
    "writer = SummaryWriter(\"logs_model\")\n",
    "start_time = time.time()\n",
    "for i in range(epoch):\n",
    "    print(\"----------第 {} 轮训练开始------------\".format(i+1))\n",
    "\n",
    "    # 训练步骤开始\n",
    "    # model.train()\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data # 获取数据\n",
    "        imgs = imgs.to(device)#####################\n",
    "        targets = targets.to(device)#########################\n",
    "        outputs = model(imgs) # 输入模型后得到预测输出\n",
    "        loss = loss_fn(outputs,targets) # 计算预测输出和数据集中的真实标签的损失\n",
    "\n",
    "        # 优化器优化模型\n",
    "        optimizer.zero_grad() # 将优化器的梯度清零\n",
    "        loss.backward() # loss反向传播\n",
    "        optimizer.step() # 开始使用优化器进行优化\n",
    "\n",
    "        total_train_step += 1 # 训练步加一\n",
    "        if total_train_step % 100 == 0:\n",
    "            end_time = time.time()\n",
    "            print(\"训练了{}次所用的时间：\".format(total_train_step),end_time-start_time)\n",
    "            print(\"训练次数: {},  Loss: {}\".format(total_train_step, loss.item()))\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), total_train_step)\n",
    "\n",
    "    # 每训练完一轮，在测试集上进行评估，判断模型的参数有没有训练好\n",
    "    # 测试步骤开始\n",
    "    # model.eval()\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 9\n",
    "    with torch.no_grad(): # 不进行调优\n",
    "        for data in test_dataloader:\n",
    "            imgs, targets = data\n",
    "            imgs = imgs.to(device)#######################\n",
    "            targets = targets.to(device)########################\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs,targets)\n",
    "            total_test_loss += loss.item()\n",
    "            accuracy = (outputs.argmax(1) == targets).sum()\n",
    "            total_accuracy += accuracy\n",
    "    test_accuracy = torch.true_divide(total_accuracy, test_data_len)\n",
    "    print(\"整体测试集上的loss： {}\".format(total_test_loss))\n",
    "    print(\"整体测试集上的正确率：{}\".format(test_accuracy))\n",
    "    writer.add_scalar(\"test_loss\", total_test_loss, total_test_step)\n",
    "    writer.add_scalar(\"test_accuracy\", test_accuracy, total_test_step)\n",
    "    total_test_step += 1\n",
    "\n",
    "    # 测试完之后保存模型的参数\n",
    "    torch.save(model,\"./weight/model_{}.pth\".format(i))\n",
    "    # torch.save(model.state_dict(), \"model_{}\".format(i)) # 官方推荐的网络模型的保存方式\n",
    "    print(\"模型已保存！\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
